{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\n\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\nimport random\nfrom tqdm.notebook import tqdm\nimport pydicom # Handle MRI images\n\nimport cv2  # OpenCV - https://docs.opencv.org/master/d6/d00/tutorial_py_root.html\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:34:46.231689Z","iopub.execute_input":"2021-10-18T09:34:46.232253Z","iopub.status.idle":"2021-10-18T09:34:51.546786Z","shell.execute_reply.started":"2021-10-18T09:34:46.232162Z","shell.execute_reply":"2021-10-18T09:34:51.546084Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Reading csv and setting data Paths","metadata":{}},{"cell_type":"code","source":"data_dir = Path('../input/rsna-miccai-brain-tumor-radiogenomic-classification/')\n\nmri_types = [\"FLAIR\", \"T1w\", \"T2w\", \"T1wCE\"]\ntrain_df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\ntest_df = pd.read_csv(data_dir / \"sample_submission.csv\")\nsample_submission = pd.read_csv(data_dir / \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:36:08.816663Z","iopub.execute_input":"2021-10-18T09:36:08.817020Z","iopub.status.idle":"2021-10-18T09:36:08.852697Z","shell.execute_reply.started":"2021-10-18T09:36:08.816970Z","shell.execute_reply":"2021-10-18T09:36:08.851774Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Functions which helps to load Dicom as 3D images","metadata":{}},{"cell_type":"code","source":"def load_dicom(path, size = 224):\n    ''' \n    Reads a DICOM image, standardizes so that the pixel values are between 0 and 1, then rescales to 0 and 255\n    \n    Not super sure if this kind of scaling is appropriate, but everyone seems to do it. \n    '''\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    # transform data into black and white scale / grayscale\n#     data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return cv2.resize(data, (size, size))\n\ndef get_all_image_paths(brats21id, image_type, folder='train'): \n    '''\n    Returns an arry of all the images of a particular type for a particular patient ID\n    '''\n    assert(image_type in mri_types)\n    \n    patient_path = os.path.join(\n        \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/%s/\" % folder, \n        str(brats21id).zfill(5),\n    )\n\n    paths = sorted(\n        glob.glob(os.path.join(patient_path, image_type, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    \n    return np.array(paths)\n\ndef get_all_images(brats21id, image_type, folder='train', size=225):\n    return [load_dicom(path, size) for path in get_all_image_paths(brats21id, image_type, folder)]\n\ndef get_all_data_for_train(image_type, image_size=32):\n    global train_df\n    \n    X = []\n    y = []\n    train_ids = []\n\n    for i in tqdm(train_df.index):\n        x = train_df.loc[i]\n        images = get_all_images(int(x['BraTS21ID']), image_type, 'train', image_size)\n        label = x['MGMT_value']\n\n        X.append(images)\n        y.append(label)\n        train_ids.append(int(x['BraTS21ID']))\n        assert(len(X) == len(y))\n    return np.array(X), np.array(y), np.array(train_ids)\n\ndef resize_volume(img, desired_depth):\n    \"\"\"Resize across z-axis\"\"\"\n    # Set the desired depth\n    desired_depth = desired_depth\n    desired_width = 128\n    desired_height = 128\n    # Get current depth\n    current_depth = img.shape[-1]\n    current_width = img.shape[0]\n    current_height = img.shape[1]\n    # Compute depth factor\n    depth = current_depth / desired_depth\n    width = current_width / desired_width\n    height = current_height / desired_height\n    depth_factor = 1 / depth\n    width_factor = 1 / width\n    height_factor = 1 / height\n    # Rotate\n    img = ndimage.rotate(img, 90, reshape=False)\n    # Resize across z-axis\n    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:36:43.775276Z","iopub.execute_input":"2021-10-18T09:36:43.775985Z","iopub.status.idle":"2021-10-18T09:36:43.793863Z","shell.execute_reply.started":"2021-10-18T09:36:43.775944Z","shell.execute_reply":"2021-10-18T09:36:43.793104Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Loading data as (width x height x depth) from Dicom","metadata":{}},{"cell_type":"code","source":"X_train, y_train, trainidt = get_all_data_for_train('FLAIR', image_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:37:21.262506Z","iopub.execute_input":"2021-10-18T09:37:21.263170Z","iopub.status.idle":"2021-10-18T09:52:49.087043Z","shell.execute_reply.started":"2021-10-18T09:37:21.263135Z","shell.execute_reply":"2021-10-18T09:52:49.086336Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train =[np.array(np.moveaxis(im, 0, -1)) for im in X_train]  # Chnage shape from (depth, width, height) to (width, height, depth(fixed size))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:52:49.088868Z","iopub.execute_input":"2021-10-18T09:52:49.089377Z","iopub.status.idle":"2021-10-18T09:52:50.355928Z","shell.execute_reply.started":"2021-10-18T09:52:49.089339Z","shell.execute_reply":"2021-10-18T09:52:50.355098Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Plot the loaded data ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(X_train[0][:,:,100])","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:52:50.357413Z","iopub.execute_input":"2021-10-18T09:52:50.357686Z","iopub.status.idle":"2021-10-18T09:52:50.613104Z","shell.execute_reply.started":"2021-10-18T09:52:50.357650Z","shell.execute_reply":"2021-10-18T09:52:50.612426Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from scipy import ndimage\n\nX_3d = []\nfor im in X_train:\n    X_3d.append(resize_volume(im, 64))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:52:50.614942Z","iopub.execute_input":"2021-10-18T09:52:50.615654Z","iopub.status.idle":"2021-10-18T09:56:12.481270Z","shell.execute_reply.started":"2021-10-18T09:52:50.615613Z","shell.execute_reply":"2021-10-18T09:56:12.480459Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_3d[64].shape","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:56:12.482703Z","iopub.execute_input":"2021-10-18T09:56:12.482967Z","iopub.status.idle":"2021-10-18T09:56:12.489736Z","shell.execute_reply.started":"2021-10-18T09:56:12.482933Z","shell.execute_reply":"2021-10-18T09:56:12.488891Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_3d[64][:,:,52])","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:56:24.517360Z","iopub.execute_input":"2021-10-18T09:56:24.518012Z","iopub.status.idle":"2021-10-18T09:56:24.742562Z","shell.execute_reply.started":"2021-10-18T09:56:24.517963Z","shell.execute_reply":"2021-10-18T09:56:24.741709Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Saving in .npy so that we can use it directly for training and other stuffs ","metadata":{}},{"cell_type":"code","source":"with open('128_FLAIR_train_X_3D_64.npy', 'wb') as f:\n    np.save(f, X_3d)\nwith open('128_FLAIR_train_y_3D_64.npy', 'wb') as f:\n    np.save(f, y_train)\nwith open('128_FLAIR_train_id_3D_64.npy', 'wb') as f:\n    np.save(f, trainidt)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:56:12.699570Z","iopub.execute_input":"2021-10-18T09:56:12.699805Z","iopub.status.idle":"2021-10-18T09:56:13.691734Z","shell.execute_reply.started":"2021-10-18T09:56:12.699774Z","shell.execute_reply":"2021-10-18T09:56:13.690963Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"len(X_3d), len(y_train), len(trainidt)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T09:56:13.693498Z","iopub.execute_input":"2021-10-18T09:56:13.693746Z","iopub.status.idle":"2021-10-18T09:56:13.700704Z","shell.execute_reply.started":"2021-10-18T09:56:13.693713Z","shell.execute_reply":"2021-10-18T09:56:13.699907Z"},"trusted":true},"execution_count":11,"outputs":[]}]}